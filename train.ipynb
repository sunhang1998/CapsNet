{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/py38/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import json\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from my_dataset import MyDataSet\n",
    "from model import swin_base_patch4_window7_224_in22k as create_model\n",
    "from utils import read_split_data, train_one_epoch, evaluate\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import math\n",
    "from torch import nn\n",
    "from apollo import Apollo\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_cycle(y1=0.0, y2=1.0, steps=100):\n",
    "    # lambda function for sinusoidal ramp from y1 to y2\n",
    "    return lambda x: ((1 - math.cos(x * math.pi / steps)) / 2) * (y2 - y1) + y1\n",
    "def main(args):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    if os.path.exists(\"./weights\") is False:\n",
    "        os.makedirs(\"./weights\")\n",
    "\n",
    "    tb_writer = SummaryWriter()\n",
    "\n",
    "    train_images_path, train_images_label, val_images_path, val_images_label = read_split_data(args.data_path)\n",
    "\n",
    "    img_size = 224\n",
    "    #预处理\n",
    "    data_transform = {\n",
    "        \"train\": transforms.Compose([transforms.RandomResizedCrop(img_size),\n",
    "                                     transforms.RandomHorizontalFlip(),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),\n",
    "        \"val\": transforms.Compose([transforms.Resize(int(img_size * 1.143)),\n",
    "                                   transforms.CenterCrop(img_size),\n",
    "                                   transforms.ToTensor(),\n",
    "                                   transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])}\n",
    "\n",
    "    # 实例化训练数据集\n",
    "    train_dataset = MyDataSet(images_path=train_images_path,\n",
    "                              images_class=train_images_label,\n",
    "                              transform=data_transform[\"train\"])\n",
    "\n",
    "    # 实例化验证数据集\n",
    "    val_dataset = MyDataSet(images_path=val_images_path,\n",
    "                            images_class=val_images_label,\n",
    "                            transform=data_transform[\"val\"])\n",
    "\n",
    "    batch_size = args.batch_size\n",
    "    nw = min([os.cpu_count(), batch_size if batch_size > 1 else 0, 8])  # number of workers\n",
    "    print('Using {} dataloader workers every process'.format(nw))\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                               batch_size=batch_size,\n",
    "                                               shuffle=True,\n",
    "                                               pin_memory=True,\n",
    "                                               num_workers=0,\n",
    "                                               collate_fn=train_dataset.collate_fn)\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset,\n",
    "                                             batch_size=batch_size,\n",
    "                                             shuffle=False,\n",
    "                                             pin_memory=True,\n",
    "                                             num_workers=0,\n",
    "                                             collate_fn=val_dataset.collate_fn)\n",
    "\n",
    "    model = create_model(num_classes=args.num_classes , input_size=[1024, 7, 7], routings=3)\n",
    "#     if torch.cuda.device_count() > 1:\n",
    "#         print(\"Use\", torch.cuda.device_count(), 'gpus')\n",
    "#         model = nn.DataParallel(model)\n",
    "#     if torch.cuda.device_count() > 1:\n",
    "#         print(\"Use\", torch.cuda.device_count(), 'gpus')\n",
    "#         model = nn.DataParallel(model, device_ids=[0,1])\n",
    "    model = model.to(device)\n",
    "#     if args.weights != \"\":\n",
    "#         assert os.path.exists(args.weights), \"weights file: '{}' not exist.\".format(args.weights)\n",
    "#         weights_dict = torch.load(args.weights, map_location=device)[\"model\"]\n",
    "#         # 删除有关分类类别的权重\n",
    "#         for k in list(weights_dict.keys()):\n",
    "#             if \"head\" in k:\n",
    "#                 del weights_dict[k]\n",
    "#         print(model.load_state_dict(weights_dict, strict=False))\n",
    "\n",
    "#     if args.freeze_layers:\n",
    "#         for name, para in model.named_parameters():\n",
    "#             # 除head外，其他权重全部冻结\n",
    "#             if \"head\" not in name:\n",
    "#                 para.requires_grad_(False)\n",
    "#             else:\n",
    "#                 print(\"training {}\".format(name))\n",
    "    pg = [p for p in model.parameters() if p.requires_grad]\n",
    "    \n",
    "\n",
    "    #optimizer = optim.AdamW(pg, lr=args.lr, betas=(0.9, 0.999), eps=5E-2, weight_decay=0.01)\n",
    "    #torch.optim.AdamW(params, lr=args.lr, betas=(0.9, 0.999), eps=1e-10, weight_decay=0.01, amsgrad=False)\n",
    "    optimizer = optim.AdamW(pg, lr=args.lr, weight_decay=5E-6)\n",
    "    #optimizer = optim.AdamW(pg, lr=args.lr, weight_decay=5E-5)\n",
    "#     optimizer = optim.Adam(pg, lr=args.lr , weight_decay=5E-5)\n",
    "    #optimizer = optim.Adam(pg, lr=args.lr , betas=0.999,eps=1e-08, weight_decay=1E-4)\n",
    "    #定义优化器\n",
    "    #通过降低损失，来更新模型权重\n",
    "    #optimizer = optim.SGD(pg, lr=args.lr, momentum=0.9, weight_decay=5E-5)\n",
    "    #optimizer = Apollo(pg, lr=args.lr, beta=0.9, eps=1e-4, rebound=args.rebound,\n",
    "                          # warmup=args.warmup_updates, init_lr=args.init_lr, weight_decay=0.)\n",
    "    lf = lambda x: ((1 + math.cos(x * math.pi / args.epochs)) / 2) * (1 - args.lrf) + args.lrf  # cosine  \n",
    "    #lf = lambda epoch:0.1*epoch\n",
    "    scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lf)\n",
    "    #epochs = args.epochs\n",
    "    #scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda epochs: 1/(epochs+1))\n",
    "    #scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    numbers = {'epoch':[],'train_loss':[],'train_acc': [], 'val_loss': [], 'val_acc': [], 'best_val':[],'lr':[]}\n",
    "    pths = []\n",
    "    best_val_acc = 0\n",
    "    v_acc = []\n",
    "    epochs = []\n",
    "    best_epoch = []\n",
    "    for epoch in range(args.epochs):\n",
    "        #optimizer.zero_grad()\n",
    "        # trai#\n",
    "        train_loss, train_acc = train_one_epoch(model=model,\n",
    "                                                optimizer=optimizer,\n",
    "                                                data_loader=train_loader,\n",
    "                                                device=device,\n",
    "                                                epoch=epoch)\n",
    "        \n",
    "        scheduler.step()     #调整学习率\n",
    "        #scheduler.step()     #调整学习率\n",
    "        # validate\n",
    "        val_loss, val_acc = evaluate(model=model,\n",
    "                                     data_loader=val_loader,\n",
    "                                     device=device,\n",
    "                                     epoch=epoch)\n",
    "        optimizer.step()   #模型的更新\n",
    "        #optimizer.step()   #模型的更新\n",
    "        epochs.append(epoch)\n",
    "        v_acc.append(val_acc)\n",
    "        numbers['epoch'].append(epoch)\n",
    "        numbers['train_loss'].append(train_loss)\n",
    "        numbers['train_acc'].append(train_acc)\n",
    "        numbers['val_loss'].append(val_loss)\n",
    "        numbers['val_acc'].append(val_acc)\n",
    "        numbers['lr'].append(optimizer.state_dict()['param_groups'][0]['lr'])\n",
    "        tags = [\"train_loss\", \"train_acc\", \"val_loss\", \"val_acc\", \"learning_rate\"]\n",
    "        tb_writer.add_scalar(tags[0], train_loss, epoch)\n",
    "        tb_writer.add_scalar(tags[1], train_acc, epoch)\n",
    "        tb_writer.add_scalar(tags[2], val_loss, epoch)\n",
    "        tb_writer.add_scalar(tags[3], val_acc, epoch)\n",
    "        tb_writer.add_scalar(tags[4], optimizer.param_groups[0][\"lr\"], epoch)\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            pths.append(model.state_dict())\n",
    "            best_epoch.append(epoch)\n",
    "            numbers['best_val'].append(val_acc)\n",
    "        if epoch == 299:\n",
    "            torch.save(model.state_dict(), \"./weights/last_model.pth\")\n",
    "        filename='databc_nobsrgan.json'\n",
    "        with open(filename,'w') as f:\n",
    "            json.dump(numbers,f)\n",
    "    print(best_epoch[len(best_epoch)-1])\n",
    "    torch.save(pths[len(pths)-1], \"./weights/best_model.pth\")\n",
    "    plt.plot(epochs,v_acc)\n",
    "    print(\"best_epoch:\",best_epoch[len(best_epoch)-1])\n",
    "\n",
    "        #torch.save(model.state_dict(), \"./weights/model-{}.pth\".format(epoch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "893 images were found in the dataset.\n",
      "715 images for training.\n",
      "178 images for validation.\n",
      "Using 8 dataloader workers every process\n",
      "  0%|          | 0/45 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 26.00 MiB (GPU 0; 10.76 GiB total capacity; 2.95 GiB already allocated; 15.12 MiB free; 3.06 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m parser\u001b[38;5;241m.\u001b[39madd_argument(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--device\u001b[39m\u001b[38;5;124m'\u001b[39m, default\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda:1\u001b[39m\u001b[38;5;124m'\u001b[39m, help\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice id (i.e. 0 or 0,1 or cpu)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     23\u001b[0m opt \u001b[38;5;241m=\u001b[39m parser\u001b[38;5;241m.\u001b[39mparse_args(args\u001b[38;5;241m=\u001b[39m[])\n\u001b[0;32m---> 25\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    102\u001b[0m best_epoch \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(args\u001b[38;5;241m.\u001b[39mepochs):\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;66;03m#optimizer.zero_grad()\u001b[39;00m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;66;03m# trai#\u001b[39;00m\n\u001b[0;32m--> 106\u001b[0m     train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep()     \u001b[38;5;66;03m#调整学习率\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;66;03m#scheduler.step()     #调整学习率\u001b[39;00m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;66;03m# validate\u001b[39;00m\n",
      "File \u001b[0;32m/data/jupyterFiles/sh/SCNet/utils.py:148\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, optimizer, data_loader, device, epoch)\u001b[0m\n\u001b[1;32m    146\u001b[0m         sample_num \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    147\u001b[0m \u001b[38;5;66;03m#         pred = model(images.to(device))\u001b[39;00m\n\u001b[0;32m--> 148\u001b[0m         labels1_pred , images_recon \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlabels1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m         pred_classes \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(labels1_pred, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    150\u001b[0m         accu_num \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39meq(pred_classes, labels\u001b[38;5;241m.\u001b[39mto(device))\u001b[38;5;241m.\u001b[39msum()\n",
      "File \u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/data/jupyterFiles/sh/SCNet/model.py:630\u001b[0m, in \u001b[0;36mSwinTransformer.forward\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    627\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_drop(x)\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m--> 630\u001b[0m     x, H, W \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mCBAM(x)\n\u001b[1;32m    632\u001b[0m H \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m7\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/data/jupyterFiles/sh/SCNet/model.py:464\u001b[0m, in \u001b[0;36mBasicLayer.forward\u001b[0;34m(self, x, H, W)\u001b[0m\n\u001b[1;32m    462\u001b[0m         x \u001b[38;5;241m=\u001b[39m checkpoint\u001b[38;5;241m.\u001b[39mcheckpoint(blk, x, attn_mask)\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 464\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mblk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownsample \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    466\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownsample(x, H, W)\n",
      "File \u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/data/jupyterFiles/sh/SCNet/model.py:376\u001b[0m, in \u001b[0;36mSwinTransformerBlock.forward\u001b[0;34m(self, x, attn_mask)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;66;03m# FFN\u001b[39;00m\n\u001b[1;32m    375\u001b[0m x \u001b[38;5;241m=\u001b[39m shortcut \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_path(x)\n\u001b[0;32m--> 376\u001b[0m x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_path(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/data/jupyterFiles/sh/SCNet/model.py:186\u001b[0m, in \u001b[0;36mMlp.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    185\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(x)\n\u001b[0;32m--> 186\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop1(x)\n\u001b[1;32m    188\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/modules/activation.py:652\u001b[0m, in \u001b[0;36mGELU.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 652\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/functional.py:1556\u001b[0m, in \u001b[0;36mgelu\u001b[0;34m(input)\u001b[0m\n\u001b[1;32m   1554\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m   1555\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(gelu, (\u001b[38;5;28minput\u001b[39m,), \u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m-> 1556\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 26.00 MiB (GPU 0; 10.76 GiB total capacity; 2.95 GiB already allocated; 15.12 MiB free; 3.06 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--num_classes', type=int, default=2)\n",
    "    parser.add_argument('--epochs', type=int, default=300)\n",
    "    parser.add_argument('--batch-size', type=int, default=16)\n",
    "    parser.add_argument('--lr', type=float, default=0.00001)#0.00001\n",
    "    parser.add_argument('--rebound', choices=['constant', 'belief'], default='constant', help='type of recified bound of diagonal hessian')\n",
    "    parser.add_argument('--lrf', type=float, default=0.001)\n",
    "    parser.add_argument('--init_lr', type=float, default=0, help='initial learning rate')\n",
    "    parser.add_argument('--warmup_updates', type=int, default=0, metavar='N', help='number of updates to warm up (default: 0)')\n",
    "    # 数据集所在根目录\n",
    "    # http://download.tensorflow.org/example_images/flower_photos.tgz\n",
    "    parser.add_argument('--data-path', type=str,\n",
    "                        default=\"../data7\")\n",
    "\n",
    "    # 预训练权重路径，如果不想载入就设置为空字符\n",
    "    parser.add_argument('--weights', type=str, default='./swin_base_patch4_window7_224_22k.pth',\n",
    "                        help='initial weights path')\n",
    "    # 是否冻结权重\n",
    "    parser.add_argument('--freeze-layers', type=bool, default=False)\n",
    "    parser.add_argument('--device', default='cuda:1', help='device id (i.e. 0 or 0,1 or cpu)')\n",
    "\n",
    "    opt = parser.parse_args(args=[])\n",
    "\n",
    "    main(opt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py38)",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
